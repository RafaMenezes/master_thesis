{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/rmenezes/miniconda3/envs/graph_simulation/lib/python3.9/site-packages/torch_geometric/typing.py:110: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: \n",
      "attribute assignment is not defined on __torch__.torch_sparse.storage.SparseStorage:\n",
      "  File \"/local/rmenezes/miniconda3/envs/graph_simulation/lib/python3.9/site-packages/torch_sparse/storage.py\", line 145\n",
      "    def empty(self):\n",
      "        self = SparseStorage.__new__(SparseStorage)\n",
      "        self._row = None\n",
      "        ~~~~~~~~~~~~~~~~ <--- HERE\n",
      "        self._rowptr = None\n",
      "        self._value = None\n",
      "\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "from learned_simulator import Simulator\n",
    "\n",
    "INPUT_SEQUENCE_LENGTH = 6\n",
    "noise_std = 6.7e-4\n",
    "with open('data/WaterRamps/metadata.json', 'rt') as f:\n",
    "    metadata = json.loads(f.read())\n",
    "\n",
    "num_steps = metadata['sequence_length'] - INPUT_SEQUENCE_LENGTH\n",
    "normalization_stats = {\n",
    "        'acceleration': {\n",
    "            'mean':torch.FloatTensor(metadata['acc_mean']).to('cuda'), \n",
    "            'std':torch.sqrt(torch.FloatTensor(metadata['acc_std'])**2 + noise_std**2).to(),\n",
    "        }, \n",
    "        'velocity': {\n",
    "            'mean':torch.FloatTensor(metadata['vel_mean']).to('cuda'), \n",
    "            'std':torch.sqrt(torch.FloatTensor(metadata['vel_std'])**2 + noise_std**2).to('cuda'),\n",
    "        }, \n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Simulator(\n",
       "  (_particle_type_embedding): Embedding(9, 16)\n",
       "  (_encode_process_decode): EncodeProcessDecode(\n",
       "    (_encoder): Encoder(\n",
       "      (node_fn): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Linear(in_features=30, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (3): ReLU()\n",
       "          (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (5): Identity()\n",
       "        )\n",
       "        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (edge_fn): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (3): ReLU()\n",
       "          (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (5): Identity()\n",
       "        )\n",
       "        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (_processor): Processor()\n",
       "    (_decoder): Decoder(\n",
       "      (node_fn): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=128, out_features=2, bias=True)\n",
       "        (5): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulator = Simulator(\n",
    "        particle_dimension=2,\n",
    "        node_in=30,\n",
    "        edge_in=3,\n",
    "        latent_dim=128,\n",
    "        num_message_passing_steps=12,\n",
    "        mlp_num_layers=2,\n",
    "        mlp_hidden_dim=128,\n",
    "        connectivity_radius=metadata['default_connectivity_radius'],\n",
    "        boundaries=np.array(metadata['bounds']),\n",
    "        normalization_stats=normalization_stats,\n",
    "        num_particle_types=9,\n",
    "        particle_type_embedding_size=16,\n",
    "        device='cuda',\n",
    "    )\n",
    "\n",
    "simulator.load('train_log/run26/model.pth')\n",
    "simulator.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-10 19:30:04.430875: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-10 19:30:05.087149: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/local/rmenezes/miniconda3/envs/graph_simulation/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "from tf_data_reader import prepare_data_from_tfds\n",
    "\n",
    "INPUT_SEQUENCE_LENGTH = 6\n",
    "\n",
    "with open('data/metadata.json', 'rt') as f:\n",
    "    metadata = json.loads(f.read())\n",
    "\n",
    "num_steps = metadata['sequence_length'] - INPUT_SEQUENCE_LENGTH\n",
    "\n",
    "\n",
    "def infer(simulator, data_path=\"data/valid.tfrecord\", device=\"cuda\"):\n",
    "    ds = prepare_data_from_tfds(data_path=data_path, is_rollout=True)\n",
    "    eval_rollout(ds, simulator, num_steps=num_steps, save_results=True, device=device)\n",
    "\n",
    "\n",
    "def eval_single_rollout(simulator, features, num_steps, device):\n",
    "    initial_positions = features['position'][:, 0:INPUT_SEQUENCE_LENGTH]\n",
    "    ground_truth_positions = features['position'][:, INPUT_SEQUENCE_LENGTH:]\n",
    "    \n",
    "    current_positions = initial_positions\n",
    "    predictions = []\n",
    "    for step in range(num_steps):\n",
    "        next_position = simulator.predict_positions(\n",
    "            current_positions,\n",
    "            n_particles_per_example=features['n_particles_per_example'],\n",
    "            particle_types=features['particle_type'],\n",
    "        ) # (n_nodes, 2)\n",
    "        # Update kinematic particles from prescribed trajectory.\n",
    "        kinematic_mask = (features['particle_type'] == 3).clone().detach().to(device)\n",
    "        next_position_ground_truth = ground_truth_positions[:, step]\n",
    "        kinematic_mask = kinematic_mask.bool()[:, None].expand(-1, 2)\n",
    "        next_position = torch.where(kinematic_mask, next_position_ground_truth, next_position)\n",
    "        predictions.append(next_position)\n",
    "        current_positions = torch.cat([current_positions[:, 1:], next_position[:, None, :]], dim=1)\n",
    "    predictions = torch.stack(predictions) # (time, n_nodes, 2)\n",
    "    ground_truth_positions = ground_truth_positions.permute(1,0,2)\n",
    "    loss = (predictions - ground_truth_positions) ** 2\n",
    "    output_dict = {\n",
    "        'initial_positions': initial_positions.permute(1,0,2).cpu().numpy(),\n",
    "        'predicted_rollout': predictions.cpu().numpy(),\n",
    "        'ground_truth_rollout': ground_truth_positions.cpu().numpy(),\n",
    "        'particle_types': features['particle_type'].cpu().numpy(),\n",
    "    }\n",
    "    return output_dict, loss\n",
    "\n",
    "\n",
    "def eval_rollout(ds, simulator, num_steps, num_eval_steps=1, save_results=False, device='cuda'):\n",
    "    eval_loss = []\n",
    "    i = 0\n",
    "    simulator.eval()\n",
    "    with torch.no_grad():\n",
    "        for example_i, (features, labels) in enumerate(ds):\n",
    "            features['position'] = torch.tensor(features['position']).to(device) # (n_nodes, 600, 2)\n",
    "            features['n_particles_per_example'] = torch.tensor(features['n_particles_per_example']).to(device)\n",
    "            features['particle_type'] = torch.tensor(features['particle_type']).to(device)\n",
    "            labels = torch.tensor(labels).to(device)\n",
    "            example_rollout, loss = eval_single_rollout(simulator, features, num_steps, device)\n",
    "            example_rollout['metadata'] = metadata\n",
    "            eval_loss.append(loss)\n",
    "            if save_results: \n",
    "                example_rollout['metadata'] = metadata\n",
    "                filename = f'rollout_{example_i}.pkl'\n",
    "                filename = os.path.join('rollouts/', filename)\n",
    "                with open(filename, 'wb') as f:\n",
    "                    pickle.dump(example_rollout, f)\n",
    "            i += 1\n",
    "            print(f'{i} / {num_eval_steps}')\n",
    "            if i >= num_eval_steps:\n",
    "                break\n",
    "    simulator.train()\n",
    "    return torch.stack(eval_loss).mean(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-10 19:30:05.723147: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-10 19:30:05.724123: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43msimulator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/WaterRamps/valid.tfrecord\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 18\u001b[0m, in \u001b[0;36minfer\u001b[0;34m(simulator, data_path, device)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minfer\u001b[39m(simulator, data_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/valid.tfrecord\u001b[39m\u001b[38;5;124m\"\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     17\u001b[0m     ds \u001b[38;5;241m=\u001b[39m prepare_data_from_tfds(data_path\u001b[38;5;241m=\u001b[39mdata_path, is_rollout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 18\u001b[0m     \u001b[43meval_rollout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimulator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 62\u001b[0m, in \u001b[0;36meval_rollout\u001b[0;34m(ds, simulator, num_steps, num_eval_steps, save_results, device)\u001b[0m\n\u001b[1;32m     60\u001b[0m features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparticle_type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparticle_type\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     61\u001b[0m labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(labels)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 62\u001b[0m example_rollout, loss \u001b[38;5;241m=\u001b[39m \u001b[43meval_single_rollout\u001b[49m\u001b[43m(\u001b[49m\u001b[43msimulator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m example_rollout[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m metadata\n\u001b[1;32m     64\u001b[0m eval_loss\u001b[38;5;241m.\u001b[39mappend(loss)\n",
      "Cell \u001b[0;32mIn[5], line 28\u001b[0m, in \u001b[0;36meval_single_rollout\u001b[0;34m(simulator, features, num_steps, device)\u001b[0m\n\u001b[1;32m     26\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_steps):\n\u001b[0;32m---> 28\u001b[0m     next_position \u001b[38;5;241m=\u001b[39m \u001b[43msimulator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_positions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcurrent_positions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_particles_per_example\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mn_particles_per_example\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparticle_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mparticle_type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (n_nodes, 2)\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# Update kinematic particles from prescribed trajectory.\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     kinematic_mask \u001b[38;5;241m=\u001b[39m (features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparticle_type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/local/rmenezes/master_thesis/learning_to_simulate_pytorch/learned_simulator.py:341\u001b[0m, in \u001b[0;36mSimulator.predict_positions\u001b[0;34m(self, current_positions, n_particles_per_example, particle_types)\u001b[0m\n\u001b[1;32m    339\u001b[0m reverse_edges_slice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    340\u001b[0m predicted_normalized_acceleration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode_process_decode(node_features, edge_index, e_features, normal_edges_slice, reverse_edges_slice)\n\u001b[0;32m--> 341\u001b[0m next_position \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decoder_postprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredicted_normalized_acceleration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_positions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m next_position\n",
      "File \u001b[0;32m/local/rmenezes/master_thesis/learning_to_simulate_pytorch/learned_simulator.py:323\u001b[0m, in \u001b[0;36mSimulator._decoder_postprocessor\u001b[0;34m(self, normalized_acceleration, position_sequence)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decoder_postprocessor\u001b[39m(\u001b[38;5;28mself\u001b[39m, normalized_acceleration, position_sequence):\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;66;03m# The model produces the output in normalized space so we apply inverse\u001b[39;00m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;66;03m# normalization.\u001b[39;00m\n\u001b[1;32m    321\u001b[0m     acceleration_stats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normalization_stats[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macceleration\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    322\u001b[0m     acceleration \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 323\u001b[0m         \u001b[43mnormalized_acceleration\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43macceleration_stats\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstd\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    324\u001b[0m     ) \u001b[38;5;241m+\u001b[39m acceleration_stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;66;03m# Use an Euler integrator to go from acceleration to position, assuming\u001b[39;00m\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;66;03m# a dt=1 corresponding to the size of the finite difference.\u001b[39;00m\n\u001b[1;32m    328\u001b[0m     most_recent_position \u001b[38;5;241m=\u001b[39m position_sequence[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "infer(\n",
    "    simulator, \n",
    "    data_path='data/WaterRamps/valid.tfrecord',\n",
    "    device='cuda'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph_simulation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
